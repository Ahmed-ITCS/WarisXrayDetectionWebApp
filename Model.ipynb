{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTl29dgnJ6xA",
        "outputId": "bf7ce473-f52a-4cb8-8517-0a341993817e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 5216 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 3s/step - accuracy: 0.7442 - loss: 0.5814 - val_accuracy: 0.5625 - val_loss: 0.9504\n",
            "Epoch 2/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 2s/step - accuracy: 0.8271 - loss: 0.3469 - val_accuracy: 0.6875 - val_loss: 0.6885\n",
            "Epoch 3/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 2s/step - accuracy: 0.8664 - loss: 0.3068 - val_accuracy: 0.7500 - val_loss: 0.6180\n",
            "Epoch 4/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 2s/step - accuracy: 0.8759 - loss: 0.2766 - val_accuracy: 0.8750 - val_loss: 0.3718\n",
            "Epoch 5/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 2s/step - accuracy: 0.8926 - loss: 0.2548 - val_accuracy: 0.8125 - val_loss: 0.4515\n",
            "Epoch 6/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 2s/step - accuracy: 0.9028 - loss: 0.2388 - val_accuracy: 0.7500 - val_loss: 0.5097\n",
            "Epoch 7/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 2s/step - accuracy: 0.9001 - loss: 0.2382 - val_accuracy: 0.7500 - val_loss: 0.8650\n",
            "Epoch 8/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 2s/step - accuracy: 0.8963 - loss: 0.2405 - val_accuracy: 0.6875 - val_loss: 0.6164\n",
            "Epoch 9/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 2s/step - accuracy: 0.9048 - loss: 0.2272 - val_accuracy: 0.7500 - val_loss: 0.4722\n",
            "Epoch 10/10\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 2s/step - accuracy: 0.8994 - loss: 0.2293 - val_accuracy: 0.6875 - val_loss: 1.0510\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 8s/step - accuracy: 0.6856 - loss: 0.8884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 81.89%\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 851ms/step\n",
            "Image 1: PNEUMONIA\n",
            "Image 2: PNEUMONIA\n",
            "Image 3: PNEUMONIA\n",
            "Image 4: NORMAL\n",
            "Image 5: NORMAL\n",
            "Image 6: PNEUMONIA\n",
            "Image 7: NORMAL\n",
            "Image 8: NORMAL\n",
            "Image 9: PNEUMONIA\n",
            "Image 10: PNEUMONIA\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the dataset on Google Drive\n",
        "data_dir = '/content/drive/MyDrive/chest_xray'  # Update with the correct path in your Drive\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'val')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "# Image data generators for preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Create data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Define the model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/pneumonia_classifier.h5')\n",
        "\n",
        "# Example: Predict on test images\n",
        "import numpy as np\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "# Display some test results\n",
        "for i in range(10):  # Show first 10 predictions\n",
        "    print(f\"Image {i+1}: {'PNEUMONIA' if predicted_classes[i] == 1 else 'NORMAL'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the dataset on Google Drive\n",
        "data_dir = '/content/drive/Lung_Opacity'  # Updated with the new folder path\n",
        "\n",
        "# Image data generators for preprocessing\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # Splitting data into training and validation\n",
        ")\n",
        "\n",
        "# Create data generators\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),  # Adjusted for ResNet50\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = data_gen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Load ResNet50 as base model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze base model layers\n",
        "\n",
        "# Build the model\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/lungopacity_resnet_classifier.h5')\n",
        "\n",
        "# Example: Predict on images\n",
        "import numpy as np\n",
        "predictions = model.predict(val_generator)\n",
        "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "# Display some results\n",
        "for i in range(10):  # Show first 10 predictions\n",
        "    print(f\"Image {i+1}: {'PNEUMONIA' if predicted_classes[i] == 1 else 'NORMAL'}\")\n"
      ],
      "metadata": {
        "id": "lviwsPaPybAZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "ad773f55-3070-4a20-d4b3-8ae86fdc489a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/Lung_Opacity'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-46dd621731ee>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Create data generators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m train_generator = data_gen.flow_from_directory(\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Adjusted for ResNet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/Lung_Opacity'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Path to the dataset on Google Drive\n",
        "data_dir = 'converted_dataset'  # Updated with the new folder path\n",
        "\n",
        "# Image data generators for preprocessing\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # Splitting data into training and validation\n",
        ")\n",
        "\n",
        "# Create data generators\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),  # Adjusted for ResNet50\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = data_gen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Load ResNet50 as base model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze base model layers\n",
        "\n",
        "# Build the model\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/lungopacity_resnet_classifier.h5')\n",
        "\n",
        "# Example: Predict on images\n",
        "import numpy as np\n",
        "predictions = model.predict(val_generator)\n",
        "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "# Display some results\n",
        "for i in range(10):  # Show first 10 predictions\n",
        "    print(f\"Image {i+1}: {'PNEUMONIA' if predicted_classes[i] == 1 else 'NORMAL'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "sbk_SGlQ4yTd",
        "outputId": "b6a1abd4-a9f8-4395-c540-2343eae509c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The PyDataset has length 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c6c01f009f62>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\u001b[0m in \u001b[0;36mget_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m             ]\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The PyDataset has length 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The PyDataset has length 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset_path = \"/content/drive/MyDrive/Lung_Opacity\"  # Ensure this matches your actual directory\n",
        "print(os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSSps_-S4HPK",
        "outputId": "62f2f95d-9be7-4f7e-dfda-c6344640e67c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['785.jpg', '243.jpg', '572.jpg', '273.jpg', '623.jpg', '298.jpg', '392.jpg', '1068.jpg', '1036.jpg', '825.jpg', '915.jpg', '910.jpg', '616.jpg', '1035.jpg', '950.jpg', '184.jpg', '360.jpg', '402.jpg', '1046.jpg', '271.jpg', '1001.jpg', '202.jpg', '721.jpg', '575.jpg', '24.jpg', '451.jpg', '813.jpg', '253.jpg', '1091.jpg', '537.jpg', '848.jpg', '676.jpg', '495.jpg', '796.jpg', '400.jpg', '470.jpg', '725.jpg', '187.jpg', '170.jpg', '157.jpg', '827.jpg', '774.jpg', '307.jpg', '581.jpg', '951.jpg', '729.jpg', '881.jpg', '437.jpg', '1101.jpg', '482.jpg', '726.jpg', '14.jpg', '1019.jpg', '141.jpg', '67.jpg', '665.jpg', '514.jpg', '1026.jpg', '62.jpg', '521.jpg', '1037.jpg', '900.jpg', '50.jpg', '647.jpg', '596.jpg', '928.jpg', '819.jpg', '918.jpg', '970.jpg', '593.jpg', '508.jpg', '301.jpg', '111.jpg', '631.jpg', '985.jpg', '913.jpg', '1093.jpg', '673.jpg', '938.jpg', '323.jpg', '501.jpg', '46.jpg', '453.jpg', '618.jpg', '1073.jpg', '836.jpg', '1098.jpg', '232.jpg', '982.jpg', '989.jpg', '933.jpg', '452.jpg', '1102.jpg', '337.jpg', '197.jpg', '1086.jpg', '341.jpg', '888.jpg', '427.jpg', '651.jpg', '274.jpg', '368.jpg', '856.jpg', '384.jpg', '115.jpg', '503.jpg', '728.jpg', '486.jpg', '415.jpg', '996.jpg', '417.jpg', '338.jpg', '61.jpg', '874.jpg', '641.jpg', '1071.jpg', '331.jpg', '226.jpg', '919.jpg', '853.jpg', '208.jpg', '543.jpg', '993.jpg', '88.jpg', '473.jpg', '610.jpg', '114.jpg', '325.jpg', '330.jpg', '245.jpg', '584.jpg', '1080.jpg', '95.jpg', '421.jpg', '180.jpg', '905.jpg', '652.jpg', '38.jpg', '733.jpg', '516.jpg', '78.jpg', '454.jpg', '724.jpg', '935.jpg', '930.jpg', '559.jpg', '234.jpg', '504.jpg', '480.jpg', '1092.jpg', '562.jpg', '483.jpg', '270.jpg', '449.jpg', '578.jpg', '786.jpg', '845.jpg', '430.jpg', '830.jpg', '667.jpg', '683.jpg', '990.jpg', '57.jpg', '799.jpg', '487.jpg', '448.jpg', '1028.jpg', '362.jpg', '456.jpg', '1067.jpg', '898.jpg', '847.jpg', '295.jpg', '834.jpg', '879.jpg', '947.jpg', '41.jpg', '828.jpg', '971.jpg', '923.jpg', '619.jpg', '75.jpg', '519.jpg', '412.jpg', '926.jpg', '650.jpg', '801.jpg', '349.jpg', '315.jpg', '527.jpg', '23.jpg', '294.jpg', '563.jpg', '85.jpg', '840.jpg', '1060.jpg', '955.jpg', '517.jpg', '433.jpg', '1048.jpg', '727.jpg', '320.jpg', '1083.jpg', '393.jpg', '556.jpg', '53.jpg', '720.jpg', '1108.jpg', '223.jpg', '227.jpg', '983.jpg', '608.jpg', '252.jpg', '497.jpg', '597.jpg', '958.jpg', '100.jpg', '77.jpg', '760.jpg', '466.jpg', '1054.jpg', '6.jpg', '304.jpg', '1123.jpg', '434.jpg', '336.jpg', '878.jpg', '791.jpg', '447.jpg', '986.jpg', '68.jpg', '112.jpg', '730.jpg', '851.jpg', '181.jpg', '116.jpg', '544.jpg', '1030.jpg', '793.jpg', '43.jpg', '409.jpg', '377.jpg', '262.jpg', '589.jpg', '626.jpg', '60.jpg', '630.jpg', '201.jpg', '940.jpg', '140.jpg', '1118.jpg', '117.jpg', '122.jpg', '957.jpg', '196.jpg', '380.jpg', '214.jpg', '1012.jpg', '272.jpg', '58.jpg', '494.jpg', '916.jpg', '678.jpg', '424.jpg', '391.jpg', '921.jpg', '143.jpg', '822.jpg', '308.jpg', '672.jpg', '1043.jpg', '1045.jpg', '812.jpg', '1125.jpg', '211.jpg', '790.jpg', '1100.jpg', '55.jpg', '284.jpg', '288.jpg', '263.jpg', '850.jpg', '408.jpg', '148.jpg', '20.jpg', '48.jpg', '31.jpg', '450.jpg', '749.jpg', '138.jpg', '159.jpg', '542.jpg', '981.jpg', '209.jpg', '809.jpg', '1081.jpg', '458.jpg', '833.jpg', '978.jpg', '564.jpg', '168.jpg', '169.jpg', '838.jpg', '906.jpg', '161.jpg', '669.jpg', '194.jpg', '762.jpg', '354.jpg', '359.jpg', '500.jpg', '644.jpg', '1013.jpg', '1015.jpg', '576.jpg', '742.jpg', '387.jpg', '1099.jpg', '766.jpg', '1089.jpg', '54.jpg', '364.jpg', '909.jpg', '489.jpg', '139.jpg', '835.jpg', '1074.jpg', '303.jpg', '754.jpg', '64.jpg', '569.jpg', '573.jpg', '535.jpg', '189.jpg', '217.jpg', '912.jpg', '49.jpg', '932.jpg', '548.jpg', '984.jpg', '719.jpg', '988.jpg', '682.jpg', '805.jpg', '1044.jpg', '709.jpg', '1113.jpg', '81.jpg', '867.jpg', '666.jpg', '737.jpg', '249.jpg', '167.jpg', '463.jpg', '317.jpg', '884.jpg', '106.jpg', '212.jpg', '776.jpg', '372.jpg', '268.jpg', '715.jpg', '660.jpg', '413.jpg', '404.jpg', '875.jpg', '1106.jpg', '339.jpg', '784.jpg', '707.jpg', '1069.jpg', '880.jpg', '859.jpg', '740.jpg', '601.jpg', '717.jpg', '47.jpg', '154.jpg', '999.jpg', '309.jpg', '472.jpg', '777.jpg', '1097.jpg', '566.jpg', '461.jpg', '134.jpg', '534.jpg', '530.jpg', '254.jpg', '322.jpg', '756.jpg', '902.jpg', '45.jpg', '1112.jpg', '1042.jpg', '532.jpg', '358.jpg', '1090.jpg', '603.jpg', '183.jpg', '787.jpg', '512.jpg', '509.jpg', '481.jpg', '351.jpg', '8.jpg', '739.jpg', '734.jpg', '239.jpg', '233.jpg', '418.jpg', '831.jpg', '477.jpg', '30.jpg', '162.jpg', '943.jpg', '492.jpg', '371.jpg', '628.jpg', '40.jpg', '370.jpg', '340.jpg', '177.jpg', '1078.jpg', '640.jpg', '87.jpg', '995.jpg', '420.jpg', '852.jpg', '745.jpg', '656.jpg', '965.jpg', '866.jpg', '771.jpg', '479.jpg', '911.jpg', '627.jpg', '590.jpg', '26.jpg', '761.jpg', '297.jpg', '738.jpg', '493.jpg', '374.jpg', '25.jpg', '885.jpg', '224.jpg', '531.jpg', '855.jpg', '1109.jpg', '1008.jpg', '108.jpg', '780.jpg', '922.jpg', '428.jpg', '670.jpg', '1107.jpg', '792.jpg', '193.jpg', '583.jpg', '638.jpg', '606.jpg', '366.jpg', '230.jpg', '904.jpg', '179.jpg', '620.jpg', '945.jpg', '2.jpg', '939.jpg', '872.jpg', '870.jpg', '344.jpg', '894.jpg', '941.jpg', '19.jpg', '241.jpg', '276.jpg', '664.jpg', '600.jpg', '281.jpg', '348.jpg', '313.jpg', '1058.jpg', '536.jpg', '375.jpg', '917.jpg', '257.jpg', '332.jpg', '1119.jpg', '1010.jpg', '164.jpg', '1052.jpg', '79.jpg', '464.jpg', '199.jpg', '639.jpg', '681.jpg', '435.jpg', '44.jpg', '716.jpg', '329.jpg', '763.jpg', '237.jpg', '229.jpg', '286.jpg', '188.jpg', '693.jpg', '598.jpg', '864.jpg', '299.jpg', '846.jpg', '455.jpg', '207.jpg', '165.jpg', '468.jpg', '545.jpg', '582.jpg', '1011.jpg', '661.jpg', '502.jpg', '1024.jpg', '869.jpg', '94.jpg', '356.jpg', '258.jpg', '18.jpg', '920.jpg', '753.jpg', '135.jpg', '849.jpg', '21.jpg', '663.jpg', '476.jpg', '1053.jpg', '491.jpg', '823.jpg', '259.jpg', '778.jpg', '744.jpg', '220.jpg', '695.jpg', '101.jpg', '789.jpg', '215.jpg', '1000.jpg', '302.jpg', '873.jpg', '176.jpg', '1072.jpg', '994.jpg', '205.jpg', '204.jpg', '126.jpg', '334.jpg', '410.jpg', '104.jpg', '705.jpg', '810.jpg', '221.jpg', '166.jpg', '897.jpg', '617.jpg', '883.jpg', '735.jpg', '552.jpg', '713.jpg', '150.jpg', '485.jpg', '467.jpg', '378.jpg', '506.jpg', '147.jpg', '129.jpg', '579.jpg', '484.jpg', '700.jpg', '936.jpg', '972.jpg', '136.jpg', '97.jpg', '973.jpg', '570.jpg', '103.jpg', '222.jpg', '557.jpg', '931.jpg', '1104.jpg', '1003.jpg', '474.jpg', '1009.jpg', '588.jpg', '153.jpg', '1117.jpg', '768.jpg', '37.jpg', '1110.jpg', '74.jpg', '533.jpg', '92.jpg', '238.jpg', '743.jpg', '595.jpg', '401.jpg', '66.jpg', '390.jpg', '9.jpg', '586.jpg', '498.jpg', '1056.jpg', '571.jpg', '191.jpg', '1116.jpg', '16.jpg', '121.jpg', '613.jpg', '686.jpg', '609.jpg', '89.jpg', '28.jpg', '113.jpg', '478.jpg', '896.jpg', '611.jpg', '877.jpg', '383.jpg', '794.jpg', '684.jpg', '72.jpg', '934.jpg', '887.jpg', '264.jpg', '185.jpg', '426.jpg', '13.jpg', '326.jpg', '255.jpg', '213.jpg', '714.jpg', '300.jpg', '422.jpg', '93.jpg', '216.jpg', '133.jpg', '702.jpg', '178.jpg', '642.jpg', '890.jpg', '11.jpg', '443.jpg', '1075.jpg', '960.jpg', '711.jpg', '462.jpg', '751.jpg', '723.jpg', '446.jpg', '246.jpg', '155.jpg', '718.jpg', '782.jpg', '275.jpg', '4.jpg', '367.jpg', '1017.jpg', '694.jpg', '109.jpg', '746.jpg', '96.jpg', '496.jpg', '118.jpg', '333.jpg', '844.jpg', '345.jpg', '747.jpg', '90.jpg', '291.jpg', '293.jpg', '59.jpg', '614.jpg', '32.jpg', '277.jpg', '653.jpg', '636.jpg', '440.jpg', '355.jpg', '518.jpg', '425.jpg', '1121.jpg', '279.jpg', '549.jpg', '292.jpg', '871.jpg', '816.jpg', '803.jpg', '131.jpg', '621.jpg', '266.jpg', '416.jpg', '1114.jpg', '927.jpg', '1124.jpg', '389.jpg', '460.jpg', '757.jpg', '804.jpg', '1018.jpg', '236.jpg', '105.jpg', '269.jpg', '35.jpg', '445.jpg', '1065.jpg', '432.jpg', '565.jpg', '511.jpg', '963.jpg', '406.jpg', '1105.jpg', '523.jpg', '699.jpg', '407.jpg', '937.jpg', '959.jpg', '395.jpg', '635.jpg', '173.jpg', '599.jpg', '632.jpg', '65.jpg', '261.jpg', '242.jpg', '12.jpg', '142.jpg', '505.jpg', '158.jpg', '436.jpg', '550.jpg', '1029.jpg', '889.jpg', '350.jpg', '594.jpg', '431.jpg', '674.jpg', '471.jpg', '1016.jpg', '127.jpg', '353.jpg', '386.jpg', '561.jpg', '541.jpg', '231.jpg', '251.jpg', '604.jpg', '1021.jpg', '658.jpg', '146.jpg', '860.jpg', '513.jpg', '977.jpg', '772.jpg', '997.jpg', '841.jpg', '33.jpg', '764.jpg', '174.jpg', '342.jpg', '980.jpg', '365.jpg', '769.jpg', '975.jpg', '82.jpg', '821.jpg', '203.jpg', '190.jpg', '29.jpg', '352.jpg', '182.jpg', '235.jpg', '629.jpg', '439.jpg', '622.jpg', '974.jpg', '520.jpg', '376.jpg', '824.jpg', '685.jpg', '396.jpg', '704.jpg', '696.jpg', '27.jpg', '228.jpg', '886.jpg', '3.jpg', '966.jpg', '648.jpg', '953.jpg', '765.jpg', '679.jpg', '256.jpg', '759.jpg', '861.jpg', '343.jpg', '84.jpg', '457.jpg', '554.jpg', '758.jpg', '901.jpg', '1115.jpg', '961.jpg', '441.jpg', '1055.jpg', '327.jpg', '553.jpg', '1040.jpg', '551.jpg', '1103.jpg', '442.jpg', '712.jpg', '423.jpg', '172.jpg', '773.jpg', '891.jpg', '649.jpg', '868.jpg', '697.jpg', '587.jpg', '278.jpg', '800.jpg', '163.jpg', '280.jpg', '908.jpg', '282.jpg', '814.jpg', '34.jpg', '946.jpg', '1057.jpg', '645.jpg', '373.jpg', '240.jpg', '969.jpg', '5.jpg', '907.jpg', '186.jpg', '529.jpg', '1087.jpg', '515.jpg', '924.jpg', '22.jpg', '637.jpg', '357.jpg', '612.jpg', '91.jpg', '558.jpg', '863.jpg', '283.jpg', '967.jpg', '750.jpg', '361.jpg', '1025.jpg', '708.jpg', '998.jpg', '1027.jpg', '36.jpg', '347.jpg', '335.jpg', '120.jpg', '748.jpg', '547.jpg', '654.jpg', '832.jpg', '1120.jpg', '624.jpg', '525.jpg', '731.jpg', '399.jpg', '119.jpg', '691.jpg', '1032.jpg', '568.jpg', '132.jpg', '1070.jpg', '469.jpg', '567.jpg', '808.jpg', '979.jpg', '312.jpg', '195.jpg', '767.jpg', '689.jpg', '346.jpg', '86.jpg', '817.jpg', '914.jpg', '942.jpg', '192.jpg', '858.jpg', '680.jpg', '952.jpg', '1007.jpg', '411.jpg', '51.jpg', '305.jpg', '602.jpg', '1006.jpg', '388.jpg', '444.jpg', '128.jpg', '152.jpg', '1041.jpg', '267.jpg', '206.jpg', '964.jpg', '625.jpg', '770.jpg', '285.jpg', '1084.jpg', '929.jpg', '130.jpg', '815.jpg', '690.jpg', '839.jpg', '363.jpg', '854.jpg', '1076.jpg', '56.jpg', '385.jpg', '110.jpg', '499.jpg', '752.jpg', '607.jpg', '722.jpg', '124.jpg', '1111.jpg', '289.jpg', '465.jpg', '643.jpg', '893.jpg', '137.jpg', '1004.jpg', '475.jpg', '706.jpg', '1050.jpg', '892.jpg', '1088.jpg', '10.jpg', '976.jpg', '876.jpg', '655.jpg', '324.jpg', '736.jpg', '83.jpg', '1096.jpg', '1002.jpg', '73.jpg', '1020.jpg', '1064.jpg', '538.jpg', '829.jpg', '102.jpg', '798.jpg', '1122.jpg', '248.jpg', '403.jpg', '144.jpg', '296.jpg', '1005.jpg', '842.jpg', '615.jpg', '1059.jpg', '692.jpg', '528.jpg', '657.jpg', '125.jpg', '321.jpg', '71.jpg', '145.jpg', '795.jpg', '398.jpg', '1033.jpg', '39.jpg', '605.jpg', '779.jpg', '63.jpg', '265.jpg', '826.jpg', '510.jpg', '149.jpg', '560.jpg', '225.jpg', '328.jpg', '968.jpg', '820.jpg', '703.jpg', '98.jpg', '405.jpg', '397.jpg', '1023.jpg', '591.jpg', '710.jpg', '797.jpg', '260.jpg', '319.jpg', '775.jpg', '490.jpg', '1031.jpg', '539.jpg', '574.jpg', '837.jpg', '1014.jpg', '171.jpg', '69.jpg', '741.jpg', '414.jpg', '175.jpg', '80.jpg', '382.jpg', '956.jpg', '659.jpg', '247.jpg', '802.jpg', '755.jpg', '903.jpg', '633.jpg', '634.jpg', '244.jpg', '419.jpg', '991.jpg', '818.jpg', '379.jpg', '895.jpg', '156.jpg', '882.jpg', '488.jpg', '76.jpg', '580.jpg', '1061.jpg', '200.jpg', '306.jpg', '1082.jpg', '198.jpg', '151.jpg', '688.jpg', '70.jpg', '546.jpg', '1038.jpg', '954.jpg', '316.jpg', '219.jpg', '732.jpg', '99.jpg', '1051.jpg', '1066.jpg', '369.jpg', '948.jpg', '1063.jpg', '1022.jpg', '52.jpg', '438.jpg', '668.jpg', '783.jpg', '675.jpg', '218.jpg', '962.jpg', '862.jpg', '646.jpg', '944.jpg', '310.jpg', '107.jpg', '592.jpg', '1095.jpg', '1034.jpg', '15.jpg', '160.jpg', '1049.jpg', '381.jpg', '1085.jpg', '250.jpg', '526.jpg', '577.jpg', '287.jpg', '1047.jpg', '865.jpg', '42.jpg', '698.jpg', '318.jpg', '7.jpg', '662.jpg', '807.jpg', '459.jpg', '857.jpg', '522.jpg', '210.jpg', '585.jpg', '1079.jpg', '925.jpg', '394.jpg', '1062.jpg', '788.jpg', '811.jpg', '987.jpg', '1039.jpg', '677.jpg', '555.jpg', '1077.jpg', '123.jpg', '671.jpg', '507.jpg', '843.jpg', '949.jpg', '290.jpg', '899.jpg', '781.jpg', '429.jpg', '992.jpg', '17.jpg', '1094.jpg', '314.jpg', '806.jpg', '540.jpg', '311.jpg', '687.jpg', '524.jpg', '701.jpg', '1.jpg']\n"
          ]
        }
      ]
    }
  ]
}
